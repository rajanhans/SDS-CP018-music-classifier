{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 - Read full features file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
      "0  blues.00000.0.wav   66149          0.335406         0.091048  0.130405   \n",
      "1  blues.00000.1.wav   66149          0.343065         0.086147  0.112699   \n",
      "2  blues.00000.2.wav   66149          0.346815         0.092243  0.132003   \n",
      "3  blues.00000.3.wav   66149          0.363639         0.086856  0.132565   \n",
      "4  blues.00000.4.wav   66149          0.335579         0.088129  0.143289   \n",
      "\n",
      "    rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
      "0  0.003521             1773.065032          167541.630869   \n",
      "1  0.001450             1816.693777           90525.690866   \n",
      "2  0.004620             1788.539719          111407.437613   \n",
      "3  0.002448             1655.289045          111952.284517   \n",
      "4  0.001701             1630.656199           79667.267654   \n",
      "\n",
      "   spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
      "0              1972.744388           117335.771563  ...   39.687145   \n",
      "1              2010.051501            65671.875673  ...   64.748276   \n",
      "2              2084.565132            75124.921716  ...   67.336563   \n",
      "3              1960.039988            82913.639269  ...   47.739452   \n",
      "4              1948.503884            60204.020268  ...   30.336359   \n",
      "\n",
      "   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \\\n",
      "0    -3.241280   36.488243     0.722209   38.099152    -5.050335   33.618073   \n",
      "1    -6.055294   40.677654     0.159015   51.264091    -2.837699   97.030830   \n",
      "2    -1.768610   28.348579     2.378768   45.717648    -1.938424   53.050835   \n",
      "3    -3.841155   28.337118     1.218588   34.770935    -3.580352   50.836224   \n",
      "4     0.664582   45.880913     1.689446   51.363583    -3.392489   26.738789   \n",
      "\n",
      "   mfcc20_mean  mfcc20_var  label  \n",
      "0    -0.243027   43.771767  blues  \n",
      "1     5.784063   59.943081  blues  \n",
      "2     2.517375   33.105122  blues  \n",
      "3     3.630866   32.023678  blues  \n",
      "4     0.536961   29.146694  blues  \n",
      "\n",
      "[5 rows x 60 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9990 entries, 0 to 9989\n",
      "Data columns (total 60 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   filename                 9990 non-null   object \n",
      " 1   length                   9990 non-null   int64  \n",
      " 2   chroma_stft_mean         9990 non-null   float64\n",
      " 3   chroma_stft_var          9990 non-null   float64\n",
      " 4   rms_mean                 9990 non-null   float64\n",
      " 5   rms_var                  9990 non-null   float64\n",
      " 6   spectral_centroid_mean   9990 non-null   float64\n",
      " 7   spectral_centroid_var    9990 non-null   float64\n",
      " 8   spectral_bandwidth_mean  9990 non-null   float64\n",
      " 9   spectral_bandwidth_var   9990 non-null   float64\n",
      " 10  rolloff_mean             9990 non-null   float64\n",
      " 11  rolloff_var              9990 non-null   float64\n",
      " 12  zero_crossing_rate_mean  9990 non-null   float64\n",
      " 13  zero_crossing_rate_var   9990 non-null   float64\n",
      " 14  harmony_mean             9990 non-null   float64\n",
      " 15  harmony_var              9990 non-null   float64\n",
      " 16  perceptr_mean            9990 non-null   float64\n",
      " 17  perceptr_var             9990 non-null   float64\n",
      " 18  tempo                    9990 non-null   float64\n",
      " 19  mfcc1_mean               9990 non-null   float64\n",
      " 20  mfcc1_var                9990 non-null   float64\n",
      " 21  mfcc2_mean               9990 non-null   float64\n",
      " 22  mfcc2_var                9990 non-null   float64\n",
      " 23  mfcc3_mean               9990 non-null   float64\n",
      " 24  mfcc3_var                9990 non-null   float64\n",
      " 25  mfcc4_mean               9990 non-null   float64\n",
      " 26  mfcc4_var                9990 non-null   float64\n",
      " 27  mfcc5_mean               9990 non-null   float64\n",
      " 28  mfcc5_var                9990 non-null   float64\n",
      " 29  mfcc6_mean               9990 non-null   float64\n",
      " 30  mfcc6_var                9990 non-null   float64\n",
      " 31  mfcc7_mean               9990 non-null   float64\n",
      " 32  mfcc7_var                9990 non-null   float64\n",
      " 33  mfcc8_mean               9990 non-null   float64\n",
      " 34  mfcc8_var                9990 non-null   float64\n",
      " 35  mfcc9_mean               9990 non-null   float64\n",
      " 36  mfcc9_var                9990 non-null   float64\n",
      " 37  mfcc10_mean              9990 non-null   float64\n",
      " 38  mfcc10_var               9990 non-null   float64\n",
      " 39  mfcc11_mean              9990 non-null   float64\n",
      " 40  mfcc11_var               9990 non-null   float64\n",
      " 41  mfcc12_mean              9990 non-null   float64\n",
      " 42  mfcc12_var               9990 non-null   float64\n",
      " 43  mfcc13_mean              9990 non-null   float64\n",
      " 44  mfcc13_var               9990 non-null   float64\n",
      " 45  mfcc14_mean              9990 non-null   float64\n",
      " 46  mfcc14_var               9990 non-null   float64\n",
      " 47  mfcc15_mean              9990 non-null   float64\n",
      " 48  mfcc15_var               9990 non-null   float64\n",
      " 49  mfcc16_mean              9990 non-null   float64\n",
      " 50  mfcc16_var               9990 non-null   float64\n",
      " 51  mfcc17_mean              9990 non-null   float64\n",
      " 52  mfcc17_var               9990 non-null   float64\n",
      " 53  mfcc18_mean              9990 non-null   float64\n",
      " 54  mfcc18_var               9990 non-null   float64\n",
      " 55  mfcc19_mean              9990 non-null   float64\n",
      " 56  mfcc19_var               9990 non-null   float64\n",
      " 57  mfcc20_mean              9990 non-null   float64\n",
      " 58  mfcc20_var               9990 non-null   float64\n",
      " 59  label                    9990 non-null   object \n",
      "dtypes: float64(57), int64(1), object(2)\n",
      "memory usage: 4.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load the features CSV file\n",
    "file_path = \"../../Misc/features_3_sec.csv\"\n",
    "full_features_df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(full_features_df.head())         # Display the first few rows\n",
    "print(full_features_df.info())         # Check for null values and data types\n",
    "#print(full_features_df.describe())     # Summary statistics for numerical columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 - Encode categorical label (genre) on the features file and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features (X): (9990, 57)\n",
      "Shape of target (y): (9990,)\n",
      "Training Features Shape: (7992, 57)\n",
      "Testing Features Shape: (1998, 57)\n",
      "Training Labels Shape: (7992,)\n",
      "Testing Labels Shape: (1998,)\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "full_features_df['label'] = label_encoder.fit_transform(full_features_df['label'])\n",
    "\n",
    "# Encode the categorical label (genre) using LabelEncoder\n",
    "X = full_features_df.drop(columns=['filename', 'label', 'length'])\n",
    "y = full_features_df['label']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# lets scale the data \n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Save the scaler and label encoder\n",
    "dump(scaler, 'scaler.joblib')\n",
    "dump(label_encoder, 'label_encoder.joblib')\n",
    "\n",
    "print(f\"Shape of features (X): {X.shape}\")\n",
    "print(f\"Shape of target (y): {y.shape}\")\n",
    "# Print dataset shapes and verify\n",
    "print(f\"Training Features Shape: {X_train.shape}\")\n",
    "print(f\"Testing Features Shape: {X_test.shape}\")\n",
    "print(f\"Training Labels Shape: {y_train.shape}\")\n",
    "print(f\"Testing Labels Shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7 - Run XGBoost Classifier on Train and Test - do not use this, use the alternate training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import seaborn as sns\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = XGBClassifier(eval_metric='mlogloss', random_state=29)\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"XGBoost Classifier\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_xgb) * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "#print(\"\\nConfusion Matrix:\")\n",
    "#print(confusion_matrix(y_test, y_pred_xgb))\n",
    "\n",
    "\n",
    "\n",
    "# # Plot confusion matrix\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(confusion_matrix(y_test, y_pred_xgb), annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "# plt.title(\"Confusion Matrix\")\n",
    "# plt.xlabel(\"Predicted\")\n",
    "# plt.ylabel(\"True\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternate code for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier\n",
      "Accuracy: 91.59%\n",
      "Recall: 91.60%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       208\n",
      "           1       0.93      0.98      0.96       203\n",
      "           2       0.85      0.88      0.86       186\n",
      "           3       0.90      0.88      0.89       199\n",
      "           4       0.94      0.90      0.92       218\n",
      "           5       0.90      0.93      0.92       192\n",
      "           6       0.94      0.97      0.96       204\n",
      "           7       0.94      0.95      0.94       180\n",
      "           8       0.95      0.91      0.93       211\n",
      "           9       0.89      0.85      0.87       197\n",
      "\n",
      "    accuracy                           0.92      1998\n",
      "   macro avg       0.92      0.92      0.92      1998\n",
      "weighted avg       0.92      0.92      0.92      1998\n",
      "\n",
      "\n",
      "Adjusted Classification Report (Threshold = 0.3):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      1.00      0.21       208\n",
      "           1       0.92      0.99      0.95       203\n",
      "           2       0.00      0.00      0.00       186\n",
      "           3       0.00      0.00      0.00       199\n",
      "           4       0.00      0.00      0.00       218\n",
      "           5       0.00      0.00      0.00       192\n",
      "           6       0.00      0.00      0.00       204\n",
      "           7       0.00      0.00      0.00       180\n",
      "           8       0.00      0.00      0.00       211\n",
      "           9       0.00      0.00      0.00       197\n",
      "\n",
      "    accuracy                           0.20      1998\n",
      "   macro avg       0.10      0.20      0.12      1998\n",
      "weighted avg       0.11      0.20      0.12      1998\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\MyWork\\Tech-Work\\SDS\\SDS-CP018-music-classifier\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\MyWork\\Tech-Work\\SDS\\SDS-CP018-music-classifier\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\MyWork\\Tech-Work\\SDS\\SDS-CP018-music-classifier\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, recall_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Initialize the XGBoost model with class imbalance handling\n",
    "xgb_model = XGBClassifier(\n",
    "    eval_metric='mlogloss', \n",
    "    random_state=29, \n",
    "    #scale_pos_weight=1,  # Set scale_pos_weight if there's class imbalance (adjust accordingly)\n",
    "    max_depth=5,         # Tuning hyperparameters for better recall\n",
    "    learning_rate=0.1,   # Tuning learning rate\n",
    "    n_estimators=1000    # Number of boosting rounds (trees)\n",
    ")\n",
    "\n",
    "# Step 2: Train the model with training data\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Predict on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Step 4: Evaluate the model using recall\n",
    "print(\"XGBoost Classifier\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_xgb) * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_xgb, average='macro') * 100:.2f}%\")  # Print recall\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "# Plot confusion matrix\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(confusion_matrix(y_test, y_pred_xgb), annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "# plt.title(\"Confusion Matrix\")\n",
    "# plt.xlabel(\"Predicted\")\n",
    "# plt.ylabel(\"True\")\n",
    "# plt.show()\n",
    "\n",
    "# Step 5: Adjust the classification threshold to increase recall\n",
    "# We will try adjusting the threshold for the positive class to get a better recall.\n",
    "threshold = 0.3  # Example threshold, you can experiment with different values\n",
    "y_pred_probs = xgb_model.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class\n",
    "y_pred_adjusted = (y_pred_probs > threshold).astype(int)  # Adjusted prediction based on threshold\n",
    "\n",
    "# Step 6: Evaluate adjusted prediction\n",
    "print(\"\\nAdjusted Classification Report (Threshold = 0.3):\")\n",
    "print(classification_report(y_test, y_pred_adjusted))\n",
    "\n",
    "# # Plot confusion matrix for adjusted threshold\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(confusion_matrix(y_test, y_pred_adjusted), annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "# plt.title(\"Adjusted Confusion Matrix (Threshold = 0.3)\")\n",
    "# plt.xlabel(\"Predicted\")\n",
    "# plt.ylabel(\"True\")\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8 - Save the XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['genre_model_xgboost_full.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Save the model to a file\n",
    "dump(xgb_model, 'genre_model_xgboost_full.joblib')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Step - Test using a sample file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.signal' has no attribute 'hann'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 83\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Step 3: Extract features from a sample input .wav file\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m#wav_file = 'klass.00010.wav'  \u001b[39;00m\n\u001b[0;32m     82\u001b[0m wav_file \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../rajan-hans/demo/Staylin_alive.wav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 83\u001b[0m extracted_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_all_features_from_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# un-comment below section for debugging purpose\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# print(f\"Extracted features (length): {len(extracted_features)}\")\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# print(f\"Extracted features: {extracted_features}\")\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Step 4: Get all feature column names from the CSV file\u001b[39;00m\n\u001b[0;32m     89\u001b[0m feature_columns \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../Misc/features_3_sec.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n",
      "Cell \u001b[1;32mIn[6], line 64\u001b[0m, in \u001b[0;36mextract_all_features_from_wav\u001b[1;34m(wav_file)\u001b[0m\n\u001b[0;32m     61\u001b[0m perceptr_var \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvar(rms)    \u001b[38;5;66;03m# Simplified perceptual variance\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Tempo (beats per minute)\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m tempo, _ \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeat_track\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# MFCCs (Mel-frequency cepstral coefficients)\u001b[39;00m\n\u001b[0;32m     67\u001b[0m mfcc \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmfcc(y\u001b[38;5;241m=\u001b[39my, sr\u001b[38;5;241m=\u001b[39msr, n_mfcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[1;32mc:\\MyWork\\Tech-Work\\SDS\\SDS-CP018-music-classifier\\.venv\\Lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32mc:\\MyWork\\Tech-Work\\SDS\\SDS-CP018-music-classifier\\.venv\\Lib\\site-packages\\librosa\\beat.py:181\u001b[0m, in \u001b[0;36mbeat_track\u001b[1;34m(y, sr, onset_envelope, hop_length, start_bpm, tightness, trim, bpm, prior, units)\u001b[0m\n\u001b[0;32m    172\u001b[0m     bpm \u001b[38;5;241m=\u001b[39m tempo(\n\u001b[0;32m    173\u001b[0m         onset_envelope\u001b[38;5;241m=\u001b[39monset_envelope,\n\u001b[0;32m    174\u001b[0m         sr\u001b[38;5;241m=\u001b[39msr,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m         prior\u001b[38;5;241m=\u001b[39mprior,\n\u001b[0;32m    178\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Then, run the tracker\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m beats \u001b[38;5;241m=\u001b[39m \u001b[43m__beat_tracker\u001b[49m\u001b[43m(\u001b[49m\u001b[43monset_envelope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbpm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtightness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m units \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\MyWork\\Tech-Work\\SDS\\SDS-CP018-music-classifier\\.venv\\Lib\\site-packages\\librosa\\beat.py:599\u001b[0m, in \u001b[0;36m__beat_tracker\u001b[1;34m(onset_envelope, bpm, fft_res, tightness, trim)\u001b[0m\n\u001b[0;32m    596\u001b[0m beats \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(beats[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    598\u001b[0m \u001b[38;5;66;03m# Discard spurious trailing beats\u001b[39;00m\n\u001b[1;32m--> 599\u001b[0m beats \u001b[38;5;241m=\u001b[39m \u001b[43m__trim_beats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocalscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m beats\n",
      "File \u001b[1;32mc:\\MyWork\\Tech-Work\\SDS\\SDS-CP018-music-classifier\\.venv\\Lib\\site-packages\\librosa\\beat.py:679\u001b[0m, in \u001b[0;36m__trim_beats\u001b[1;34m(localscore, beats, trim)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__trim_beats\u001b[39m(localscore, beats, trim):\n\u001b[0;32m    677\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Final post-processing: throw out spurious leading/trailing beats\"\"\"\u001b[39;00m\n\u001b[1;32m--> 679\u001b[0m     smooth_boe \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39msignal\u001b[38;5;241m.\u001b[39mconvolve(localscore[beats], \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhann\u001b[49m(\u001b[38;5;241m5\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trim:\n\u001b[0;32m    682\u001b[0m         threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m ((smooth_boe \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'scipy.signal' has no attribute 'hann'"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "import pandas as pd\n",
    "import scipy.signal\n",
    "from scipy.signal.windows import hann\n",
    "\n",
    "# Add hann to scipy.signal for backward compatibility\n",
    "scipy.signal.hann = hann\n",
    "\n",
    "# Step 1: Load the pre-trained XGBoost model, scaler, and label encoder\n",
    "xgb_model = load('genre_model_xgboost_full.joblib')\n",
    "scaler = load('scaler.joblib')\n",
    "label_encoder = load('label_encoder.joblib')\n",
    "\n",
    "# Define the genre names corresponding to the encoded labels\n",
    "genre_names = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "\n",
    "# Step 2: Function to extract all features from a .wav file\n",
    "def extract_all_features_from_wav(wav_file):\n",
    "    # Load audio file using librosa\n",
    "    y, sr = librosa.load(wav_file, sr=None)  # sr=None preserves the original sample rate\n",
    "    \n",
    "    # Extract various audio features (matching CSV columns)\n",
    "    \n",
    "    # Length of the audio (duration in seconds)\n",
    "    #length = librosa.get_duration(y=y, sr=sr)\n",
    "    \n",
    "    # Spectral Bandwidth\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    spectral_bandwidth_mean = np.mean(spectral_bandwidth)\n",
    "    spectral_bandwidth_var = np.var(spectral_bandwidth)\n",
    "    \n",
    "    # Chroma STFT (Short-Time Fourier Transform)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    chroma_stft_mean = np.mean(chroma_stft)\n",
    "    chroma_stft_var = np.var(chroma_stft)\n",
    "    \n",
    "    # RMS (Root Mean Square)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    rms_mean = np.mean(rms)\n",
    "    rms_var = np.var(rms)\n",
    "    \n",
    "    # Spectral Centroid\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spectral_centroid_mean = np.mean(spectral_centroid)\n",
    "    spectral_centroid_var = np.var(spectral_centroid)\n",
    "    \n",
    "    # Roll-off (Spectral roll-off point)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr, roll_percent=0.85)\n",
    "    rolloff_mean = np.mean(rolloff)\n",
    "    rolloff_var = np.var(rolloff)\n",
    "    \n",
    "    # Zero-Crossing Rate\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=y)\n",
    "    zero_crossing_rate_mean = np.mean(zero_crossing_rate)\n",
    "    zero_crossing_rate_var = np.var(zero_crossing_rate)\n",
    "    \n",
    "    # Harmony (harmonic-to-noise ratio)\n",
    "    harmony = librosa.effects.harmonic(y)\n",
    "    harmony_mean = np.mean(harmony)\n",
    "    harmony_var = np.var(harmony)\n",
    "    \n",
    "    # Perceptual features\n",
    "    perceptr_mean = np.mean(rms)  # Simplified perceptual mean\n",
    "    perceptr_var = np.var(rms)    # Simplified perceptual variance\n",
    "    \n",
    "    # Tempo (beats per minute)\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    \n",
    "    # MFCCs (Mel-frequency cepstral coefficients)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    mfcc_features = [np.mean(mfcc[i]) for i in range(20)] + [np.var(mfcc[i]) for i in range(20)]\n",
    "    \n",
    "    # Combine all extracted features\n",
    "    features = [\n",
    "        chroma_stft_mean, chroma_stft_var, rms_mean, rms_var,\n",
    "        spectral_centroid_mean, spectral_centroid_var, spectral_bandwidth_mean, spectral_bandwidth_var,\n",
    "        rolloff_mean, rolloff_var, zero_crossing_rate_mean, zero_crossing_rate_var,\n",
    "        harmony_mean, harmony_var, perceptr_mean, perceptr_var, tempo\n",
    "    ] + mfcc_features\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Step 3: Extract features from a sample input .wav file\n",
    "#wav_file = 'klass.00010.wav'  \n",
    "wav_file ='../rajan-hans/demo/Staylin_alive.wav'\n",
    "extracted_features = extract_all_features_from_wav(wav_file)\n",
    "# un-comment below section for debugging purpose\n",
    "# print(f\"Extracted features (length): {len(extracted_features)}\")\n",
    "# print(f\"Extracted features: {extracted_features}\")\n",
    "\n",
    "# Step 4: Get all feature column names from the CSV file\n",
    "feature_columns = pd.read_csv(\"../../Misc/features_3_sec.csv\").columns.tolist()\n",
    "\n",
    "# un-comment below section for debugging purpose\n",
    "#print(f\"Feature columns from CSV (length): {len(feature_columns)}\")\n",
    "\n",
    "# Step 5: Clean the feature columns (remove 'label' and 'filename')\n",
    "feature_columns.remove('label')\n",
    "feature_columns.remove('filename')\n",
    "feature_columns.remove('length')\n",
    "\n",
    "# un-comment below section for debugging purpose\n",
    "#print(f\"Feature columns after cleaning (length): {len(feature_columns)}\")\n",
    "\n",
    "# un-comment below section for debugging purpose\n",
    "# # Step 6: Compare the number of extracted features to the expected number of features\n",
    "# if len(extracted_features) != len(feature_columns):\n",
    "#     print(f\"Warning: Number of extracted features ({len(extracted_features)}) does not match the expected number of features ({len(feature_columns)})\")\n",
    "#     print(f\"Extracted Features: {extracted_features}\")\n",
    "#     print(f\"Feature Columns from CSV: {feature_columns}\")\n",
    "# else:\n",
    "#     print(\"Number of extracted features matches the expected columns.\")\n",
    "\n",
    "# un-comment for debugging purpose\n",
    "#for i in range(len(feature_columns)):\n",
    "#    print(f\"{feature_columns[i]}: {extracted_features[i]}\")\n",
    "\n",
    "# Step 7: Create a DataFrame with the correct columns\n",
    "extracted_features_df = pd.DataFrame([extracted_features], columns=feature_columns)\n",
    "\n",
    "# Step 8: Scale the extracted features using the saved scaler\n",
    "X_scaled = scaler.transform(extracted_features_df)\n",
    "\n",
    "# Step 9: Use the trained model to predict the genre\n",
    "predicted_label_encoded = xgb_model.predict(X_scaled)\n",
    "\n",
    "# Step 10: Decode the predicted label to get the genre name\n",
    "#predicted_label = label_encoder.inverse_transform(predicted_label_encoded)\n",
    "\n",
    "# Step 11: Map the encoded label to the actual genre name\n",
    "predicted_genre_name = genre_names[predicted_label_encoded[0]]  # Map the predicted label to the actual genre name\n",
    "\n",
    "# Step 12: Print the predicted genre\n",
    "print(f\"The predicted genre of the song {wav_file} is: {predicted_genre_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
