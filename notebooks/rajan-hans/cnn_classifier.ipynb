{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TensorFlow is used for building the CNN model, while \n",
    "# scikit-learn is used for data preprocessing. \n",
    "# Pandas handles data manipulation \n",
    "# and joblib is used to save model components (scaler and label encoder).\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Reshape, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib  # For saving scaler and label encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and extract features and labels from provided features_3_sec csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(\"../../Misc/features_3_sec.csv\")\n",
    "X = features_df.drop(columns=['filename','label','length']).values  # Drop 'label' column and take all features\n",
    "y = features_df['label'].values  # 'label' column contains the target classes (genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spilt into Train and Test, Encode and Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoder saved successfully.\n",
      "Scaler saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# ML models generally work with numerical data, so we need to encode the music genres (which are categorical) into numerical labels. \n",
    "# The LabelEncoder will map each unique genre to an integer.\n",
    "label_encoder = LabelEncoder()\n",
    "features_df['label'] = label_encoder.fit_transform(features_df['label'])\n",
    "\n",
    "# Save the label encoder o it can be reused after transforming the labels later (for model inference).\n",
    "# Save the label encoder as pkl\n",
    "joblib.dump(label_encoder, 'label_encoder_cnn.pkl')\n",
    "# Save the label encoder as joblib\n",
    "dump(label_encoder, 'label_encoder_cnn.joblib')\n",
    "\n",
    "print(\"LabelEncoder saved successfully.\")\n",
    "\n",
    "\n",
    "#Split the datset into features and labels\n",
    "X = features_df.drop(columns=['filename', 'label', 'length']) # Drop unnecessary columns including length as that is constant  \n",
    "y = features_df['label']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Scale the data after splitting so that Test data does not have visibility\n",
    "# Normalization across instances should be done after splitting the data \n",
    "# between training and test set, using only the data from the training set.\n",
    "# This is because the test set plays the role of fresh unseen data, \n",
    "# so it's not supposed to be accessible at the training stage. \n",
    "# Using any information coming from the test set before or during training \n",
    "# is a potential bias in the evaluation of the performance.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Save the scaler so it can be reused after transforming the features\n",
    "# Save the scaler as pkl\n",
    "joblib.dump(scaler, 'scaler_cnn.pkl')\n",
    "# Save the scaler as joblib\n",
    "dump(scaler, 'scaler_cnn.joblib')\n",
    "print(\"Scaler saved successfully.\")\n",
    "\n",
    "# print(f\"Shape of features (X): {X.shape}\")\n",
    "# print(f\"Shape of target (y): {y.shape}\")\n",
    "# # Print dataset shapes and verify\n",
    "# print(f\"Training Features Shape: {X_train.shape}\")\n",
    "# print(f\"Testing Features Shape: {X_test.shape}\")\n",
    "# print(f\"Training Labels Shape: {y_train.shape}\")\n",
    "# print(f\"Testing Labels Shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the CNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\MyWork\\Tech-Work\\SDS\\SDS-CP018-music-classifier\\.venv\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,586</span> (221.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m56,586\u001b[0m (221.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,394</span> (220.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m56,394\u001b[0m (220.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Reshape the input to have a 3D shape (samples, timesteps, features) for Conv1D layers\n",
    "# We add an extra dimension since Conv1D expects a 3D input.\n",
    "model.add(Reshape((X_train.shape[1], 1), input_shape=(X_train.shape[1],)))\n",
    "\n",
    "# First Conv1D layer with 32 filters, a kernel size of 3, ReLU activation, and L2 regularization\n",
    "model.add(Conv1D(32, 3, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "# Batch normalization to help stabilize training by normalizing activations\n",
    "model.add(BatchNormalization())\n",
    "# Max-pooling layer to down-sample the feature map\n",
    "model.add(MaxPooling1D(2))\n",
    "\n",
    "# Second Conv1D layer with 64 filters, kernel size of 3, ReLU activation, and L2 regularization\n",
    "model.add(Conv1D(64, 3, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "# Another max-pooling layer\n",
    "model.add(MaxPooling1D(2))\n",
    "\n",
    "# Flatten the feature map to create a 1D vector, which is required for the dense layers\n",
    "model.add(Flatten())\n",
    "# Dense layer with 64 units, ReLU activation, and L2 regularization\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "# Dropout layer to prevent overfitting by randomly dropping 30% of the neurons\n",
    "model.add(Dropout(0.3))\n",
    "# Output layer with softmax activation for multi-class classification\n",
    "model.add(Dense(len(np.unique(y)), activation='softmax'))\n",
    "\n",
    "# Compile the model using Adam optimizer with a learning rate of 0.001 and sparse categorical cross-entropy loss\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define early stopping callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping is a callback function that helps prevent overfitting by stopping \n",
    "# the training process if the validation loss doesn't improve after a certain \n",
    "# number of epochs (patience=5). This will restore the best weights based on \n",
    "# the validation performance.\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.4143 - loss: 1.9766 - val_accuracy: 0.4840 - val_loss: 1.7549\n",
      "Epoch 2/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6758 - loss: 1.1284 - val_accuracy: 0.6612 - val_loss: 1.2494\n",
      "Epoch 3/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7301 - loss: 0.9431 - val_accuracy: 0.7643 - val_loss: 0.9305\n",
      "Epoch 4/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7808 - loss: 0.7977 - val_accuracy: 0.7963 - val_loss: 0.7825\n",
      "Epoch 5/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8071 - loss: 0.7195 - val_accuracy: 0.8158 - val_loss: 0.7335\n",
      "Epoch 6/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8290 - loss: 0.6564 - val_accuracy: 0.8298 - val_loss: 0.6820\n",
      "Epoch 7/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8648 - loss: 0.5765 - val_accuracy: 0.8443 - val_loss: 0.6439\n",
      "Epoch 8/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8677 - loss: 0.5472 - val_accuracy: 0.8388 - val_loss: 0.6389\n",
      "Epoch 9/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8819 - loss: 0.5102 - val_accuracy: 0.8488 - val_loss: 0.6151\n",
      "Epoch 10/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8951 - loss: 0.4707 - val_accuracy: 0.8564 - val_loss: 0.5950\n",
      "Epoch 11/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9062 - loss: 0.4395 - val_accuracy: 0.8634 - val_loss: 0.5957\n",
      "Epoch 12/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9142 - loss: 0.4263 - val_accuracy: 0.8664 - val_loss: 0.5806\n",
      "Epoch 13/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9209 - loss: 0.4017 - val_accuracy: 0.8724 - val_loss: 0.5523\n",
      "Epoch 14/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9331 - loss: 0.3791 - val_accuracy: 0.8724 - val_loss: 0.5735\n",
      "Epoch 15/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9322 - loss: 0.3619 - val_accuracy: 0.8749 - val_loss: 0.5597\n",
      "Epoch 16/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9326 - loss: 0.3608 - val_accuracy: 0.8704 - val_loss: 0.5667\n",
      "Epoch 17/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9407 - loss: 0.3484 - val_accuracy: 0.8729 - val_loss: 0.5756\n",
      "Epoch 18/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9434 - loss: 0.3353 - val_accuracy: 0.8649 - val_loss: 0.6042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#train the model using the training data.\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# save the model to disk using the .save() method. \n",
    "model.save('music_genre_cnn_model.h5')\n",
    "\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 - 0s - 2ms/step - accuracy: 0.8724 - loss: 0.5523\n",
      "Test accuracy: 0.8724\n"
     ]
    }
   ],
   "source": [
    "# evaluate the trained model on the test set to determine its performance \n",
    "# in terms of accuracy. This gives us an indication of how well the model \n",
    "# generalizes to unseen data.\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot training history for accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training and validation accuracy and loss over epochs to visualize \n",
    "# how the model improved during training. This can help identify potential \n",
    "# issues like overfitting or underfitting.\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy over epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss over epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1\n",
      "before step 2\n",
      "just before returning in step 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "The predicted genre of the song ../rajan-hans/demo/Staylin_alive.wav is: rock\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Step 1: Load the pre-trained CNN model, scaler, and label encoder\n",
    "model = load_model('music_genre_cnn_model.h5')\n",
    "scaler = load('scaler_cnn.joblib')\n",
    "label_encoder = load('label_encoder_cnn.joblib')\n",
    "print(\"step 1\")\n",
    "# Define the genre names corresponding to the encoded labels\n",
    "genre_names = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "\n",
    "print(\"before step 2\")\n",
    "# Step 2: Function to extract all features from a .wav file\n",
    "def extract_all_features_from_wav(wav_file):\n",
    "    # Load audio file using librosa\n",
    "    y, sr = librosa.load(wav_file, sr=None)  # sr=None preserves the original sample rate\n",
    "    \n",
    "    # Extract various audio features (matching CSV columns)\n",
    "    \n",
    "    # Length of the audio (duration in seconds)\n",
    "    #length = librosa.get_duration(y=y, sr=sr)\n",
    "    \n",
    "    # Spectral Bandwidth\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    spectral_bandwidth_mean = np.mean(spectral_bandwidth)\n",
    "    spectral_bandwidth_var = np.var(spectral_bandwidth)\n",
    "    \n",
    "    # Chroma STFT (Short-Time Fourier Transform)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    chroma_stft_mean = np.mean(chroma_stft)\n",
    "    chroma_stft_var = np.var(chroma_stft)\n",
    "    \n",
    "    # RMS (Root Mean Square)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    rms_mean = np.mean(rms)\n",
    "    rms_var = np.var(rms)\n",
    "    \n",
    "    # Spectral Centroid\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spectral_centroid_mean = np.mean(spectral_centroid)\n",
    "    spectral_centroid_var = np.var(spectral_centroid)\n",
    "    \n",
    "    # Roll-off (Spectral roll-off point)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr, roll_percent=0.85)\n",
    "    rolloff_mean = np.mean(rolloff)\n",
    "    rolloff_var = np.var(rolloff)\n",
    "    \n",
    "    # Zero-Crossing Rate\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=y)\n",
    "    zero_crossing_rate_mean = np.mean(zero_crossing_rate)\n",
    "    zero_crossing_rate_var = np.var(zero_crossing_rate)\n",
    "    \n",
    "    # Harmony (harmonic-to-noise ratio)\n",
    "    harmony = librosa.effects.harmonic(y)\n",
    "    harmony_mean = np.mean(harmony)\n",
    "    harmony_var = np.var(harmony)\n",
    "    \n",
    "    # Perceptual features\n",
    "    perceptr_mean = np.mean(rms)  # Simplified perceptual mean\n",
    "    perceptr_var = np.var(rms)    # Simplified perceptual variance\n",
    "    \n",
    "    # Tempo (beats per minute)\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    \n",
    "    # MFCCs (Mel-frequency cepstral coefficients)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    mfcc_features = [np.mean(mfcc[i]) for i in range(20)] + [np.var(mfcc[i]) for i in range(20)]\n",
    "    \n",
    "    # Combine all extracted features\n",
    "    features = [\n",
    "        chroma_stft_mean, chroma_stft_var, rms_mean, rms_var,\n",
    "        spectral_centroid_mean, spectral_centroid_var, spectral_bandwidth_mean, spectral_bandwidth_var,\n",
    "        rolloff_mean, rolloff_var, zero_crossing_rate_mean, zero_crossing_rate_var,\n",
    "        harmony_mean, harmony_var, perceptr_mean, perceptr_var, tempo\n",
    "    ] + mfcc_features\n",
    "    \n",
    "    print(\"just before returning in step 2\")\n",
    "    return features\n",
    "\n",
    "# Step 3: Extract features from a sample input .wav file\n",
    "#wav_file = 'klass.00010.wav'  \n",
    "wav_file ='../rajan-hans/demo/Staylin_alive.wav'\n",
    "extracted_features = extract_all_features_from_wav(wav_file)\n",
    "# un-comment below section for debugging purpose\n",
    "# print(f\"Extracted features (length): {len(extracted_features)}\")\n",
    "# print(f\"Extracted features: {extracted_features}\")\n",
    "\n",
    "# Step 4: Get all feature column names from the CSV file\n",
    "feature_columns = pd.read_csv(\"../../Misc/features_3_sec.csv\").columns.tolist()\n",
    "\n",
    "# un-comment below section for debugging purpose\n",
    "#print(f\"Feature columns from CSV (length): {len(feature_columns)}\")\n",
    "\n",
    "# Step 5: Clean the feature columns (remove 'label' and 'filename')\n",
    "feature_columns.remove('label')\n",
    "feature_columns.remove('filename')\n",
    "feature_columns.remove('length')\n",
    "\n",
    "# un-comment below section for debugging purpose\n",
    "#print(f\"Feature columns after cleaning (length): {len(feature_columns)}\")\n",
    "\n",
    "# un-comment below section for debugging purpose\n",
    "# # Step 6: Compare the number of extracted features to the expected number of features\n",
    "# if len(extracted_features) != len(feature_columns):\n",
    "#     print(f\"Warning: Number of extracted features ({len(extracted_features)}) does not match the expected number of features ({len(feature_columns)})\")\n",
    "#     print(f\"Extracted Features: {extracted_features}\")\n",
    "#     print(f\"Feature Columns from CSV: {feature_columns}\")\n",
    "# else:\n",
    "#     print(\"Number of extracted features matches the expected columns.\")\n",
    "\n",
    "# un-comment for debugging purpose\n",
    "#for i in range(len(feature_columns)):\n",
    "#    print(f\"{feature_columns[i]}: {extracted_features[i]}\")\n",
    "\n",
    "# Step 7: Create a DataFrame with the correct columns\n",
    "extracted_features_df = pd.DataFrame([extracted_features], columns=feature_columns)\n",
    "\n",
    "# Step 8: Scale the extracted features using the saved scaler\n",
    "X_scaled = scaler.transform(extracted_features_df)\n",
    "\n",
    "# # Step 9: Use the trained model to predict the genre\n",
    "# predicted_label_encoded = model.predict(X_scaled)\n",
    "\n",
    "# print(\"step 9\")\n",
    "# # Step 10: Decode the predicted label to get the genre name\n",
    "# predicted_label = label_encoder.inverse_transform(predicted_label_encoded)\n",
    "\n",
    "# # Step 11: Map the encoded label to the actual genre name\n",
    "# predicted_genre_name = genre_names[predicted_label_encoded[0]]  # Map the predicted label to the actual genre name\n",
    "\n",
    "# # Step 12: Print the predicted genre\n",
    "# print(f\"The predicted genre of the song {wav_file} is: {predicted_genre_name}\")\n",
    "\n",
    "\n",
    "# Step 9: Predict the genre\n",
    "predicted_label_encoded = model.predict(X_scaled)\n",
    "predicted_label_index = np.argmax(predicted_label_encoded, axis=1)[0]\n",
    "\n",
    "# Step 10-12: Map and print the genre\n",
    "if predicted_label_index < len(genre_names):\n",
    "    predicted_genre_name = genre_names[predicted_label_index]\n",
    "    print(f\"The predicted genre of the song {wav_file} is: {predicted_genre_name}\")\n",
    "else:\n",
    "    print(f\"Error: Predicted label {predicted_label_index} is out of range.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
